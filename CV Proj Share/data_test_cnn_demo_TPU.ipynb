{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"data_test_cnn_demo_TPU.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"}},"cells":[{"cell_type":"code","metadata":{"id":"8oG7Kp4GwpSQ"},"source":["# For Google Colaboratory\n","import sys, os\n","if 'google.colab' in sys.modules:\n","    # mount google drive\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","    # find automatically the path of the folder containing \"file_name\" :\n","    file_name = 'data_test_demo.ipynb'\n","    import subprocess\n","    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n","    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n","    # if previous search failed or too long, comment the previous line and simply write down manually the path below :\n","    print(path_to_file)\n","    # change current path to the folder containing \"file_name\"\n","    os.chdir(path_to_file)\n","    !pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8Tc_siIwPZT"},"source":["import os\n","assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n","DIST_BUCKET=\"gs://tpu-pytorch/wheels\"\n","TORCH_WHEEL=\"torch-1.15-cp36-cp36m-linux_x86_64.whl\"\n","TORCH_XLA_WHEEL=\"torch_xla-1.15-cp36-cp36m-linux_x86_64.whl\"\n","TORCHVISION_WHEEL=\"torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl\"\n","\n","# Install Colab TPU compat PyTorch/TPU wheels and dependencies\n","!pip uninstall -y torch torchvision\n","!gsutil cp \"$DIST_BUCKET/$TORCH_WHEEL\" .\n","!gsutil cp \"$DIST_BUCKET/$TORCH_XLA_WHEEL\" .\n","!gsutil cp \"$DIST_BUCKET/$TORCHVISION_WHEEL\" .\n","!pip install \"$TORCH_WHEEL\"\n","!pip install \"$TORCH_XLA_WHEEL\"\n","!pip install \"$TORCHVISION_WHEEL\"\n","!sudo apt-get install libomp5\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71SWaABWwj1h"},"source":["import pandas as pd\n","from sklearn import model_selection\n","from sklearn.preprocessing import MinMaxScaler\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from random import randint\n","import time\n","import utils\n","import torch_xla\n","import torch_xla.core.xla_model as xm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwEZbZ-xwj1s"},"source":["df = pd.read_csv(\"A_Z Handwritten Data.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkCAPgXawj1v"},"source":["for i in range(1, 10):\n","    print(df.iloc[60000 + i, 0])\n","    plt.subplot(5, 5, i)\n","    digit = np.array(df.iloc[60000 + i, 1:])\n","    plt.imshow(digit.reshape(28, 28))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiWShw9Bv4-K"},"source":["device=xm.xla_device()\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1hT0paQwj1z"},"source":["data_feature, data_label = np.array(df.iloc[:, 1:]), np.array(df.iloc[:, 0])\n","train_data, test_data, train_label, test_label = model_selection.train_test_split(\n","    data_feature, data_label, test_size=0.05, random_state=75)\n","ss = MinMaxScaler()\n","train_data = ss.fit_transform(train_data)\n","test_data = ss.fit_transform(test_data)\n","\n","train_data = (torch.Tensor(train_data.reshape(-1,28,28)))\n","test_data = (torch.Tensor(test_data.reshape(-1,28,28)))\n","train_label = torch.LongTensor(train_label)\n","test_label = torch.LongTensor(test_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzfufTyBkpHU"},"source":["mean= train_data.mean()\n","std= train_data.std()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MSenEfBhwj11"},"source":["class two_layer_net(nn.Module):\n","    def __init__(self):\n","        super(two_layer_net, self).__init__()\n","\n","        \n","        self.conv1 = nn.Conv2d(1,   26,  kernel_size=3,  padding=1 )\n","        \n","        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n","        self.pool1  = nn.MaxPool2d(2,2)\n","        \n","        # CL2:   50 x 14 x 14  -->    100 x 14 x 14 \n","        self.conv2 = nn.Conv2d(26,  50,  kernel_size=3,  padding=1 )\n","        \n","        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n","        self.pool2 = nn.MaxPool2d(2,2)\n","        \n","        # LL1:   100 x 7 x 7 = 4900 -->  100 \n","        self.linear1 = nn.Linear(2450, 50)\n","        \n","        # LL2:   100  -->  10 \n","        self.linear2 = nn.Linear(50,26)\n","\n","\n","    def forward(self, x):\n","\n","        # CL1:   28 x 28  -->    50 x 28 x 28 \n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        \n","        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n","        x = self.pool1(x)\n","        \n","        # CL2:   50 x 14 x 14  -->    100 x 14 x 14\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        \n","        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n","        x = self.pool2(x)\n","\n","        # LL1:   100 x 7 x 7 = 4900  -->  100 \n","        x = x.view(-1, 2450)\n","        x = self.linear1(x)\n","        x = F.relu(x)\n","        \n","        # LL2:   4900  -->  10 \n","        x = self.linear2(x)\n","    \n","        return x\n","       "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6zHQlOxwj16"},"source":["net = two_layer_net()\n","net=net.to(xm.xla_device())\n","print(net)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJVfkIypwj18"},"source":["criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","\n","bs = 10000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cx77uLFywj1_"},"source":["def eval_on_test_set():\n","    bs=100\n","    running_error = 0\n","    num_batches = 0\n","\n","    for i in range(0, 18600, bs):\n","\n","        minibatch_data =  test_data[i:i+bs].unsqueeze(dim=1)\n","        minibatch_label= test_label[i:i+bs]\n","        \n","        inputs = (minibatch_data - mean)/std\n","\n","        scores = net(inputs)\n","\n","        error = utils.get_error(scores, minibatch_label)\n","\n","        running_error += error.item()\n","\n","        num_batches += 1\n","\n","    total_error = running_error / num_batches\n","    print('test error  = ', total_error * 100, 'percent')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zku_T5orwj2C"},"source":["start = time.time()\n","\n","for epoch in range(200):\n","\n","    running_loss = 0\n","    running_error = 0\n","    num_batches = 0\n","\n","    shuffled_indices = torch.randperm(350000)\n","\n","    for count in range(0, 350000, bs):\n","\n","        # forward and backward pass\n","\n","        optimizer.zero_grad()\n","\n","        indices = shuffled_indices[count:count + bs]\n","        minibatch_data =  train_data[indices].unsqueeze(dim=1)\n","        minibatch_label=  train_label[indices]\n","        \n","        inputs = (minibatch_data - mean)/std\n","\n","        inputs.requires_grad_()\n","\n","        scores = net(inputs)\n","\n","        loss = criterion(scores, minibatch_label)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        # compute some stats\n","\n","        running_loss += loss.detach().item()\n","\n","        error = utils.get_error(scores.detach(), minibatch_label)\n","        running_error += error.item()\n","\n","        num_batches += 1\n","\n","    # once the epoch is finished we divide the \"running quantities\"\n","    # by the number of batches\n","\n","    total_loss = running_loss / num_batches\n","    total_error = running_error / num_batches\n","    elapsed_time = time.time() - start\n","\n","    # every 10 epoch we display the stats\n","    # and compute the error rate on the test set\n","\n","    if epoch % 5 == 0:\n","\n","        print(' ')\n","\n","        print('epoch=', epoch, '\\t time=', elapsed_time, '\\t loss=',\n","              total_loss, '\\t error=', total_error * 100, 'percent')\n","\n","        eval_on_test_set()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0y3SfKOwj2E"},"source":["# choose a picture at random\n","idx=np.random.randint(0, 18600)\n","im=test_data[idx]\n","\n","# diplay the picture\n","utils.show(im)\n","\n","# feed it to the net and display the confidence scores\n","scores =  net( im.view(1,784)) \n","probs= F.softmax(scores, dim=1)\n","# utils.show_prob_mnist(probs)\n","\n","# alphabets table\n","alphabets=[chr(i) for i in range(97,123)]\n","print(alphabets[probs.argmax()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v4NzvI6Pwj2G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0m5eLwBNwj2I"},"source":[""],"execution_count":null,"outputs":[]}]}