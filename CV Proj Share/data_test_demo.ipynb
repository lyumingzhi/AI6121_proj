{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oG7Kp4GwpSQ"
   },
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    # find automatically the path of the folder containing \"file_name\" :\n",
    "    file_name = 'data_test_demo.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    # if previous search failed or too long, comment the previous line and simply write down manually the path below :\n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71SWaABWwj1h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwEZbZ-xwj1s"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"A_Z Handwritten Data.csv\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkCAPgXawj1v"
   },
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    print(df.iloc[60000 + i, 0])\n",
    "    plt.subplot(5, 5, i)\n",
    "    digit = np.array(df.iloc[60000 + i, 1:])\n",
    "    plt.imshow(digit.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1hT0paQwj1z"
   },
   "outputs": [],
   "source": [
    "data_feature, data_label = np.array(df.iloc[:, 1:]), np.array(df.iloc[:, 0])\n",
    "train_data, test_data, train_label, test_label = model_selection.train_test_split(\n",
    "    data_feature, data_label, test_size=0.05, random_state=75)\n",
    "ss = MinMaxScaler()\n",
    "train_data = ss.fit_transform(train_data)\n",
    "test_data = ss.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0z8IrDAzUUk"
   },
   "outputs": [],
   "source": [
    "train_data = (torch.Tensor(train_data.reshape(-1,28,28))).to(device)\n",
    "test_data = (torch.Tensor(test_data.reshape(-1,28,28))).to(device)\n",
    "train_label = (torch.LongTensor(train_label)).to(device)\n",
    "test_label = (torch.LongTensor(test_label)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSenEfBhwj11"
   },
   "outputs": [],
   "source": [
    "class two_layer_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(two_layer_net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y = self.layer1(x)\n",
    "        y_hat = F.relu(y)\n",
    "        scores = self.layer2(y_hat)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6zHQlOxwj16"
   },
   "outputs": [],
   "source": [
    "net = two_layer_net(784, 50, 26)\n",
    "net = net.to(device)\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJVfkIypwj18"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "\n",
    "bs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx77uLFywj1_"
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "    bs=100\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i in range(0, 18600, bs):\n",
    "\n",
    "        minibatch_data = test_data[i:i + bs]\n",
    "        minibatch_label = test_label[i:i + bs]\n",
    "\n",
    "        inputs = (minibatch_data).view(bs, 784)\n",
    "\n",
    "        scores = net(inputs)\n",
    "\n",
    "        error = utils.get_error(scores, minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    total_error = running_error / num_batches\n",
    "    print('test error  = ', total_error * 100, 'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zku_T5orwj2C"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(800):\n",
    "\n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    shuffled_indices = torch.randperm(350000)\n",
    "\n",
    "    for count in range(0, 350000, bs):\n",
    "\n",
    "        # forward and backward pass\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = shuffled_indices[count:count + bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "\n",
    "        inputs = minibatch_data.view(bs, 784)\n",
    "\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores = net(inputs)\n",
    "\n",
    "        loss = criterion(scores, minibatch_label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # compute some stats\n",
    "\n",
    "        running_loss += loss.detach().item()\n",
    "\n",
    "        error = utils.get_error(scores.detach(), minibatch_label)\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    # once the epoch is finished we divide the \"running quantities\"\n",
    "    # by the number of batches\n",
    "\n",
    "    total_loss = running_loss / num_batches\n",
    "    total_error = running_error / num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "\n",
    "    # every 10 epoch we display the stats\n",
    "    # and compute the error rate on the test set\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        print(' ')\n",
    "\n",
    "        print('epoch=', epoch, '\\t time=', elapsed_time, '\\t loss=',\n",
    "              total_loss, '\\t error=', total_error * 100, 'percent')\n",
    "\n",
    "        eval_on_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0y3SfKOwj2E"
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "# choose a picture at random\n",
    "idx=np.random.randint(0, 18600)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im.cpu())\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net( im.view(1,784)) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "utils.show_prob_alphabets(probs.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4NzvI6Pwj2G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0m5eLwBNwj2I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data_test_demo.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
